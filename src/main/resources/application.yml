spring:
  ai:
    openai:
      api-key: "${OPENAI_API_KEY:not-needed}"
      base-url: "${OPENAI_BASE_URL:http://localhost:1234/}"
      chat:
        options:
          model: "${DEFAULT_MODEL:local-model}"
          temperature: "${AI_TEMPERATURE:0.1}"
          max-tokens: 2000

server:
  error:
    include-stacktrace: never
    include-message: never
  port: 8080
  servlet:
    session:
      tracking-modes: cookie
      cookie:
        secure: false
        http-only: true
        same-site: strict
      timeout: 30m
  shutdown: graceful

logging:
  level:
    org.springframework.ai: WARN

cache:
  model-discovery:
    duration-minutes: "${CACHE_MODEL_DISCOVERY_DURATION_MINUTES:5}"
    
